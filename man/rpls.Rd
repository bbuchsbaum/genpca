% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rpls.R
\name{fit_rpls}
\alias{fit_rpls}
\alias{rpls}
\title{Regularised / Generalised Partial Least Squares (RPLS / GPLS)}
\usage{
fit_rpls(
  X,
  Y,
  K = 2,
  lambda = 0.1,
  penalty = c("l1", "ridge"),
  Q = NULL,
  nonneg = FALSE,
  tol = 1e-06,
  maxiter = 200,
  verbose = FALSE
)

rpls(
  X,
  Y,
  K = 2,
  lambda = 0.1,
  penalty = c("l1", "ridge"),
  Q = NULL,
  nonneg = FALSE,
  preproc_x = pass(),
  preproc_y = pass(),
  tol = 1e-06,
  maxiter = 200,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{X}{Numeric matrix \eqn{(n \times p)} — predictors.}

\item{Y}{Numeric matrix \eqn{(n \times q)} — responses.}

\item{K}{Integer, number of latent factors to extract. Default `2`.}

\item{lambda}{Scalar or length-\code{K} numeric vector of penalties.}

\item{penalty}{Either `"l1"` (lasso) or `"ridge"`.}

\item{Q}{Optional positive-(semi)definite \eqn{p \times p} matrix
inducing *generalised* PLS. `NULL` ⇒ identity.}

\item{nonneg}{Logical, force non-negative loadings when
\code{penalty = "l1"}. Note: This option is currently ignored when
\code{penalty = "ridge"}.}

\item{tol}{Relative tolerance for the inner iterations convergence check.
Default `1e-6`.}

\item{maxiter}{Maximum number of inner iterations per component. Default `200`.}

\item{verbose}{Logical; print progress messages during component extraction.
Default `FALSE`.}

\item{preproc_x, }{preproc_y Optional \pkg{multivarious} preprocessing
objects (see \code{\link[multivarious]{prep}}). By default they pass
the data through unchanged using \code{pass()}.}

\item{...}{Further arguments (e.g., custom stopping criteria if implemented)
are stored in the returned object (they are not used by
\code{fit_rpls}).}
}
\value{
An object of class \code{c("rpls","cross_projector","projector")}
  with at least the elements
  \describe{
    \item{vx}{\eqn{p \times K} matrix of X-loadings.}
    \item{vy}{\eqn{q \times K} matrix of Y-loadings.}
    \item{ncomp}{Number of components actually extracted (may be < K).}
    \item{penalty}{Penalty type used (`"l1"` or `"ridge"`).}
    \item{preproc_x, preproc_y}{Pre-processing transforms used.}
    \item{...}{Other parameters like `lambda`, `tol`, `maxiter`, `nonneg`,
               `Q` indicator, `verbose` are also stored.}
  }

  The object supports \code{predict()}, \code{project()},
  \code{transfer()}, \code{coef()} and other \pkg{multivarious} generics.
}
\description{
Implements the algorithm of Allen *et al.* (2013) for supervised
dimension-reduction with optional sparsity (\eqn{\ell_1}) or ridge
(\eqn{\ell_2}) penalties **and** the generalised extension that operates
in a user-supplied quadratic form \eqn{Q}.
}
\details{
Unlike `genpls()` from \code{genplsr.R}, which handles separate row and
column metrics (`Mx`, `Ax`, `My`, `Ay`) with a Gram–Schmidt orthogonalisation
step, `rpls()` uses a single metric `Q` and the simpler penalised updates of
Allen et al.
}
\section{Method}{

The routine follows Algorithm 1 of Allen *et al.* (2013, *Stat.
Anal. Data Min.*, 6 : 302–314) — see the paper for details. Briefly,
each component maximises
\deqn{\max_{u,v}\; v^\top Q M u - \lambda \, P(v)}
with \eqn{Q = I_p} for standard RPLS. The alternating updates are:
\eqn{u \leftarrow M^\top Q v / \|M^\top Q v\|_2}, then a penalised
(possibly non-negative) regression for \eqn{v}, normalised in the
\eqn{Q}-norm.
}

\examples{
# Generate sample data
set.seed(123)
n <- 50
p <- 20
q <- 10
X <- matrix(rnorm(n * p), n, p)
Y <- X[, 1:5] \%*\% matrix(rnorm(5 * q), 5, q) + matrix(rnorm(n * q), n, q)

# Fit regularized PLS with L1 penalty
fit_l1 <- rpls(X, Y, K = 3, lambda = 0.1, penalty = "l1")
print(fit_l1)

# Fit regularized PLS with ridge penalty
fit_ridge <- rpls(X, Y, K = 3, lambda = 0.1, penalty = "ridge")
print(fit_ridge)

}
\references{
Allen, G. I., Peterson, C., Vannucci, M., &
  Maletić-Savatić, M. (2013). *Regularized Partial Least Squares with
  an Application to NMR Spectroscopy.* **Statistical Analysis and Data
  Mining, 6(4)**, 302-314. DOI:10.1002/sam.11169.
}
\keyword{internal}
