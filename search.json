[{"path":[]},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"summary","dir":"","previous_headings":"Report 1: NA Eigenvalue Errors in prep_constraints Function","what":"Summary","title":"genpca Package Test Failure Bug Reports","text":"genpca package experiencing failures prep_constraints function eigenvalue computations either failing completely (returning NA) returning negative eigenvalues matrices positive semi-definite (PSD). affects multiple test cases involving sparse constraint matrices.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"primary-issues-identified","dir":"","previous_headings":"Report 1: NA Eigenvalue Errors in prep_constraints Function > Root Cause Analysis","what":"Primary Issues Identified:","title":"genpca Package Test Failure Bug Reports","text":"RSpectra eigenvalue computation failures: prep_constraints function uses RSpectra::eigs_sym(, k=1, =\"SA\") find smallest eigenvalue. failing several scenarios, particularly sparse matrices created neighborweights package functions. Non-PSD matrices external dependencies: Test cases creating constraint matrices using neighborweights package functions guaranteed positive semi-definite: neighborweights:::adjacency.neighbor_graph() creates adjacency matrices temporal_adjacency() followed t() %*% operations matrices may negative eigenvalues numerical issues Missing dependency: neighborweights package used extensively tests listed DESCRIPTION dependency (Suggests Imports). Eigenvalue tolerance issues: current tolerance 1e-8 may strict numerically challenging sparse matrices.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"specific-failing-tests-analysis","dir":"","previous_headings":"Report 1: NA Eigenvalue Errors in prep_constraints Function","what":"Specific Failing Tests Analysis:","title":"genpca Package Test Failure Bug Reports","text":"M matrix created neighborweights adjacency graph diag(M) <- 1.5 Error: smallest eigenvalue = -0.0283834767954287 Large temporal adjacency matrix (10000x10000) Error: NA (eigenvalue computation failed) Temporal adjacency matrix t() %*% 500x500 matrix Error: NA (eigenvalue computation failed) Sparse adjacency matrix spatial grid Error: smallest eigenvalue = -3.75877048314363","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"impact-assessment","dir":"","previous_headings":"Report 1: NA Eigenvalue Errors in prep_constraints Function","what":"Impact Assessment","title":"genpca Package Test Failure Bug Reports","text":"Severity: High - Core functionality broken realistic use cases Scope: - Affects users using spatial/temporal constraints - Breaks large-scale applications sparse constraint matrices - 4 critical test failures main functionality","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"proposed-solutions","dir":"","previous_headings":"Report 1: NA Eigenvalue Errors in prep_constraints Function","what":"Proposed Solutions","title":"genpca Package Test Failure Bug Reports","text":"Add better fallback strategies RSpectra fails Implement robust matrix conditioning checks Use multiple eigenvalue computation methods Implement regularization near-singular matrices Add automatic matrix conditioning (e.g., ridge penalty) Provide better error messages suggested fixes Add neighborweights Suggests DESCRIPTION replace internal functions test matrix generation","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"summary-1","dir":"","previous_headings":"Report 2: dsyMatrix C++ Compatibility Error in gmd_fast_cpp","what":"Summary","title":"genpca Package Test Failure Bug Reports","text":"gmd_fast_cpp function genpca package fails passed dense symmetric matrices (dsyMatrix objects) R’s Matrix package, throwing error “dsyMatrix supported”. error occurs automatic type conversion R C++ RcppArmadillo.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"technical-root-cause","dir":"","previous_headings":"Report 2: dsyMatrix C++ Compatibility Error in gmd_fast_cpp","what":"Technical Root Cause","title":"genpca Package Test Failure Bug Reports","text":"issue stems incompatible matrix type handling R’s Matrix package RcppArmadillo’s automatic type conversion system: Matrix Type Creation: Matrix::Matrix() called dense, symmetric, positive-definite matrix, automatically creates dsyMatrix object - specialized class dense symmetric matrices. C++ Function Signature: gmd_fast_cpp function expects arma::sp_mat (sparse matrix) types Q R constraint matrices: Conversion Failure: RcppArmadillo’s automatic conversion system convert dsyMatrix object arma::sp_mat, resulting “dsyMatrix supported” error.","code":"List gmd_fast_cpp(const arma::mat& X,                   const arma::sp_mat& Q,    // <-- expects sparse matrix                   const arma::sp_mat& R,    // <-- expects sparse matrix                   int k, ...)"},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"failing-tests","dir":"","previous_headings":"Report 2: dsyMatrix C++ Compatibility Error in gmd_fast_cpp","what":"Failing Tests","title":"genpca Package Test Failure Bug Reports","text":"test_gpca.R:309 - “gmd_fast_cpp matches genpca (use_cpp=TRUE) p <= n, dense constraints” test_gpca.R:329 - “gmd_fast_cpp matches genpca (use_cpp=TRUE) p > n, dense constraints”","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"impact-assessment-1","dir":"","previous_headings":"Report 2: dsyMatrix C++ Compatibility Error in gmd_fast_cpp","what":"Impact Assessment","title":"genpca Package Test Failure Bug Reports","text":"Severity: High - Core C++ functionality completely broken dense constraint matrices - Multiple critical tests failing - Users use fast C++/Spectra implementation dense constraints","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"proposed-solution","dir":"","previous_headings":"Report 2: dsyMatrix C++ Compatibility Error in gmd_fast_cpp","what":"Proposed Solution","title":"genpca Package Test Failure Bug Reports","text":"Modify C++ function accept SEXP parameters handle type conversion explicitly:","code":"// In gmd_fast.cpp List gmd_fast_cpp(const arma::mat& X,                   SEXP Q_sexp,          // Accept raw SEXP                   SEXP R_sexp,          // Accept raw SEXP                     int k, double tol = 1e-9, int maxit = 1000, int seed = 1234) {     // Convert Q to sparse matrix with proper type handling     arma::sp_mat Q;     if (Rf_inherits(Q_sexp, \"dsyMatrix\") || Rf_inherits(Q_sexp, \"dgeMatrix\")) {         // Convert dense Matrix to sparse         arma::mat Q_dense = Rcpp::as<arma::mat>(Q_sexp);         Q = arma::sp_mat(Q_dense);     } else {         Q = Rcpp::as<arma::sp_mat>(Q_sexp);     }          // Similar handling for R     // ... rest of function }"},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"summary-2","dir":"","previous_headings":"Report 3: Numerical Precision Issues in genpca Package Tests","what":"Summary","title":"genpca Package Test Failure Bug Reports","text":"Multiple test failures genpca R package occurring due numerical precision algorithmic issues across several core functions. failures span matrix decomposition algorithms, generalized eigenvalue solvers, sparse functional PCA, subspace comparison utilities.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_1-generalized-eigenvalue-problem-solver-solve_gep_subspace","dir":"","previous_headings":"Report 3: Numerical Precision Issues in genpca Package Tests > Root Cause Analysis","what":"1. Generalized Eigenvalue Problem Solver (solve_gep_subspace)","title":"genpca Package Test Failure Bug Reports","text":"Issue: Gram matrix orthogonality check failing large deviations expected identity matrices. Technical cause: - subspace iteration algorithm maintaining proper orthogonality S2-inner product - orthonormalization step uses standard QR decomposition use generalized inner product - Regularization parameters may inadequate ill-conditioned matrices Evidence:","code":"gram matrix expected: diag(3) = [1,0,0; 0,1,0; 0,0,1] gram matrix actual: [0.375, *, 3.496; *, 0.581, *; *, *, *]"},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_2-sparse-functional-pca-sfpca","dir":"","previous_headings":"Report 3: Numerical Precision Issues in genpca Package Tests > Root Cause Analysis","what":"2. Sparse Functional PCA (sfpca)","title":"genpca Package Test Failure Bug Reports","text":"Issue: Rank-1 matrix recovery severely inaccurate large magnitude errors. Technical cause: - alternating optimization algorithm converging true rank-1 decomposition - Regularization penalties insufficient test case - Sign ambiguity handling inadequate Evidence:","code":"Expected singular value: 17.4 Actual singular value: 1.3 Error magnitude: 92.5% relative error"},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_3-c-vs-r-implementation-mismatches-gmd_fast_cpp","dir":"","previous_headings":"Report 3: Numerical Precision Issues in genpca Package Tests > Root Cause Analysis","what":"3. C++ vs R Implementation Mismatches (gmd_fast_cpp)","title":"genpca Package Test Failure Bug Reports","text":"Issue: Subspace correlation matrices C++ R implementations close permutation matrices. Technical cause: - Different numerical precision algorithmic paths C++ R implementations - Possible differences eigenvalue/singular value solver convergence criteria - Sign convention inconsistencies implementations","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"common-patterns-across-failures","dir":"","previous_headings":"Report 3: Numerical Precision Issues in genpca Package Tests","what":"Common Patterns Across Failures:","title":"genpca Package Test Failure Bug Reports","text":"Orthogonality Loss: Multiple algorithms fail maintain proper orthogonality constraints Regularization Inadequacy: Default regularization parameters appear insufficient test matrices Sign Ambiguity: Inconsistent handling sign indeterminacy matrix decompositions Tolerance Mismatches: Test tolerances don’t match actual numerical precision algorithms Implementation Divergence: C++ R implementations produce different results identical inputs","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"proposed-solutions-1","dir":"","previous_headings":"Report 3: Numerical Precision Issues in genpca Package Tests","what":"Proposed Solutions","title":"genpca Package Test Failure Bug Reports","text":"Implement proper generalized Gram-Schmidt orthogonalization solve_gep_subspace Replace standard QR S2-orthogonal QR decomposition Implement adaptive regularization based matrix condition numbers Add condition number monitoring warnings Increase default regularization parameters Review convergence criteria alternating optimization Implement better initialization strategies Improve penalty parameter estimation heuristics Ensure C++ R implementations use identical algorithms tolerances Add comprehensive cross-validation tests implementations Standardize sign conventions across matrix decomposition functions","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"summary-3","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues","what":"Summary","title":"genpca Package Test Failure Bug Reports","text":"genpca R package experiencing several critical test failures related missing imports, method dispatch issues, dimension mismatches rpls (regularized partial least squares) transfer method implementations.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_1-missing-function-imports-primary-issue","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues > Root Cause Analysis","what":"1. Missing Function Imports (Primary Issue)","title":"genpca Package Test Failure Bug Reports","text":"Problem: package import essential functions multivarious: - project function imported, causing Error: find function \"project\" - partial_project function imported, causing Error: object 'partial_project' found Evidence: /Users/bbuchsbaum/code/genpca/NAMESPACE imports limited functions multivarious","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_2-method-dispatch-and-gets3method-issue","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues > Root Cause Analysis","what":"2. Method Dispatch and getS3method Issue","title":"genpca Package Test Failure Bug Reports","text":"Problem: /Users/bbuchsbaum/code/genpca/R/transfer_wrappers.R line 43 uses getS3method() without importing utils package.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_3-s3-method-signature-inconsistency","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues > Root Cause Analysis","what":"3. S3 Method Signature Inconsistency","title":"genpca Package Test Failure Bug Reports","text":"Problem: transfer.cross_projector method parameter name mismatches base multivarious implementation.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"failing-tests-1","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues","what":"Failing Tests","title":"genpca Package Test Failure Bug Reports","text":"test_rpls.R:176 - “rpls partial projection works partial cols requested” - Dimension mismatch test_gpca.R:29 - “gen_pca column variances equivalent scaled pca” - Attributes length mismatch Package check warnings S3 method consistency Note undefined global function ‘getS3method’","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"impact-assessment-2","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues","what":"Impact Assessment","title":"genpca Package Test Failure Bug Reports","text":"Severity: HIGH - Multiple core functionality tests failing - Package fails basic R CMD check requirements - Method dispatch broken transfer operations","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_1-fix-namespace-imports-critical---priority-1","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues > Proposed Solutions","what":"1. Fix NAMESPACE Imports (Critical - Priority 1)","title":"genpca Package Test Failure Bug Reports","text":"Add missing imports /Users/bbuchsbaum/code/genpca/NAMESPACE:","code":"importFrom(multivarious,project) importFrom(multivarious,partial_project) importFrom(utils,getS3method)"},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_2-fix-transfer_wrappersr-method-critical---priority-1","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues > Proposed Solutions","what":"2. Fix transfer_wrappers.R Method (Critical - Priority 1)","title":"genpca Package Test Failure Bug Reports","text":"Add /Users/bbuchsbaum/code/genpca/R/transfer_wrappers.R:","code":"#' @importFrom utils getS3method"},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"id_3-standardize-parameter-names-medium---priority-2","dir":"","previous_headings":"Report 4: RPLS and Transfer Method Issues > Proposed Solutions","what":"3. Standardize Parameter Names (Medium - Priority 2)","title":"genpca Package Test Failure Bug Reports","text":"Ensure parameter signature consistency transfer methods.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"summary-statistics","dir":"","previous_headings":"","what":"Summary Statistics","title":"genpca Package Test Failure Bug Reports","text":"Total Test Failures: 34 Categories: 4 major issue categories Severity: HIGH severity Missing imports dependencies Matrix type compatibility issues Numerical precision problems Algorithm implementation differences","code":""},{"path":"https://bbuchsbaum.github.io/genpca/BUG_REPORTS.html","id":"recommended-action-plan","dir":"","previous_headings":"","what":"Recommended Action Plan","title":"genpca Package Test Failure Bug Reports","text":"Fix NAMESPACE imports Add missing dependencies DESCRIPTION Fix getS3method import Fix dsyMatrix C++ compatibility Improve eigenvalue computation robustness Fix generalized orthogonalization Standardize C++/R implementations Improve SFPCA convergence Update test tolerances Add comprehensive numerical diagnostics Improve documentation Add user guidance edge cases","code":""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"CLAUDE.md","text":"genpca R package implementing Generalized Principal Component Analysis related matrix decompositions. package provides methods generalized PCA row column constraints, well generalized partial least squares techniques.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"building-and-installing-the-package","dir":"","previous_headings":"Development Commands","what":"Building and Installing the Package","title":"CLAUDE.md","text":"","code":"# Install package with devtools (as configured in .Rproj) R -e \"devtools::install()\"  # Build and check package R CMD build . R CMD check genpca_*.tar.gz  # Install dependencies R -e \"install.packages(c('Rcpp', 'RcppArmadillo', 'RcppEigen', 'RSpectra', 'FNN', 'Matrix', 'multivarious', 'assertthat'))\""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"running-tests","dir":"","previous_headings":"Development Commands","what":"Running Tests","title":"CLAUDE.md","text":"","code":"# Run all tests R -e \"testthat::test_package('genpca')\"  # Run tests for a specific file R -e \"testthat::test_file('tests/testthat/test_gpca.R')\"  # Run tests with coverage R -e \"covr::package_coverage()\""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"development-workflow","dir":"","previous_headings":"Development Commands","what":"Development Workflow","title":"CLAUDE.md","text":"","code":"# Load package for interactive development R -e \"devtools::load_all()\"  # Generate documentation from roxygen comments R -e \"devtools::document()\"  # Check package R -e \"devtools::check()\""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"core-components","dir":"","previous_headings":"Architecture","what":"Core Components","title":"CLAUDE.md","text":"gpca.R: Generalized PCA implementation constraint handling gep_subspace.R: Generalized eigenvalue problem subspace methods sfpca.R: Sparse functional PCA rpls.R: Regularized partial least squares plsutils.R: Utility functions PLS methods transfer_methods.R: Core transfer learning implementations transfer_wrappers.R: High-level wrappers transfer methods gpca.cpp: Core GPCA algorithms C++ gmd_fast.cpp: Fast generalized matrix decomposition Uses RcppArmadillo RcppEigen efficient linear algebra","code":""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"key-design-patterns","dir":"","previous_headings":"Architecture","what":"Key Design Patterns","title":"CLAUDE.md","text":"Constraint Handling: prep_constraints() function gpca.R validates prepares constraint matrices (M), ensuring positive semi-definite various remediation strategies. S3 Class System: Methods follow R’s S3 object system classes like genpca, cross_projector, projector. Integration multivarious: package extends multivarious package’s framework dimensionality reduction methods.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"testing-strategy","dir":"","previous_headings":"Architecture","what":"Testing Strategy","title":"CLAUDE.md","text":"Tests use testthat framework organized functionality: - Basic functionality tests (e.g., test_gpca.R) - Algorithm soundness checks (e.g., test_genpls_alg_soundness.R) - Edge case handling (e.g., test_deflation_empty.R) - Integration tests transfer learning methods","code":""},{"path":"https://bbuchsbaum.github.io/genpca/CLAUDE.html","id":"important-notes","dir":"","previous_headings":"Architecture","what":"Important Notes","title":"CLAUDE.md","text":"package uses sparse matrix representations Matrix package extensively Constraint matrices must positive semi-definite; package provides multiple remediation strategies experimental/ directory contains work--progress implementations Package follows R CMD check standards proper NAMESPACE management","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"genpca: Generalized PCA and Related Decompositions","text":"Principal Component Analysis (PCA) one widely used techniques data analysis, providing foundation dimensionality reduction, data visualization, feature extraction. vignette introduces Generalized PCA (GPCA), powerful extension adapts PCA natural geometry data. practical examples clear explanations, ’ll learn move beyond standard PCA unlock deeper insights complex datasets.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"why-generalized-pca","dir":"Articles","previous_headings":"Introduction","what":"Why Generalized PCA?","title":"genpca: Generalized PCA and Related Decompositions","text":"Standard Principal Component Analysis (PCA) assumes variables observations equally important Euclidean distance captures relevant notion similarity. However, many real-world applications violate assumptions. Consider survey data observation represents responses populations vastly different sizes. Standard PCA treat response representing 10,000 people identically one representing 100 people, potentially distorting true population-level patterns. Similarly, variables measured different precisions—perhaps expensive high-accuracy instruments others approximate methods—need framework can incorporate measurement characteristics directly analysis. challenge extends beyond simple weighting. spatial temporal data, variables often exhibit known correlation structures inform dimensionality reduction. temperature measurement one location naturally correlated nearby locations, ignoring structure can lead misleading components. Furthermore, many specialized domains functional data analysis shape analysis operate inherently non-Euclidean spaces standard PCA’s assumptions break entirely. Generalized PCA (GPCA) addresses limitations extending PCA framework incorporate row column metric constraints encode prior knowledge data structure. principled approach allows us perform dimensionality reduction respects natural geometry problem domain.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"what-is-generalized-pca","dir":"Articles","previous_headings":"Introduction","what":"What is Generalized PCA?","title":"genpca: Generalized PCA and Related Decompositions","text":"genpca package implements Generalized PCA related matrix decompositions data observed non‑Euclidean inner‑product spaces. core, GPCA transforms standard PCA problem introducing two symmetric positive semi‑definite (PSD) matrices fundamentally alter measure distances angles data space. Given n × p data matrix X, row metric M (n × n matrix) defines inner product observation space. metric induces M‑norm ||x||_M^2 = x^T M x determines measure distances observations d_M(x, y)^2 = (x − y)^T M (x − y). working weighted sampling, might choose M diagonal matrix observation weights. data known correlation structure among observations, M might encode precision (inverse covariance) relationships. applications involving temporal spatial data, M kernel matrix capturing smoothness assumptions. Analogously, column metric (p × p matrix) defines inner product variable space, inducing ||v||_A^2 = v^T v distance d_A(v, w)^2 = (v − w)^T (v − w). metric might encode feature importance diagonal weights, capture known relationships variables covariance precision matrices, represent graph‑based connectivity network data. key insight correlations similarities encoded metrics inner products, dissimilarities emerge naturally induced distances. M = I_n = I_p (identity matrices), recover standard PCA special case, confirming GPCA true generalization encompasses familiar enabling much .","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"package-capabilities","dir":"Articles","previous_headings":"Introduction","what":"Package Capabilities","title":"genpca: Generalized PCA and Related Decompositions","text":"genpca package provides comprehensive toolkit generalized matrix decompositions. heart genpca() function, implements GPCA multiple computational backends tailored different problem scales structures. small--medium datasets forming full matrices feasible, method = \"eigen\" option provides direct eigendecomposition excellent numerical stability. dealing large-scale sparse data, method = \"spectra\" backend leverages matrix-free iterative solvers implemented C++ exceptional scalability. situations components needed massive datasets, method = \"deflation\" extracts components sequentially, minimizing memory footprint. Beyond core decomposition, package handles practical challenges working metric constraints. automatically validates , necessary, repairs metric matrices ensure positive semi-definiteness, using sophisticated remediation strategies preserve much original structure possible. robustness means can focus statistical modeling rather numerical details. package integrates seamlessly multivarious ecosystem, providing unified workflow preprocessing, projection, reconstruction, transfer learning across different dimensionality reduction methods. integration extends Generalized Partial Least Squares genpls() function, enabling canonical correlation analysis related two-block methods full metric support. vignette introduces GPCA concepts practical examples demonstrates core usage patterns. interested mathematical foundations, particularly connections PLS-SVD whitening transformations, companion vignette “Generalized PLS-SVD: Explicit Whitening Reference” provides detailed theoretical derivations.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"mathematical-formulation","dir":"Articles","previous_headings":"","what":"Mathematical Formulation","title":"genpca: Generalized PCA and Related Decompositions","text":"conceptual foundation place, let’s examine mathematical formulation makes GPCA theoretically sound computationally tractable.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"the-generalized-pca-problem","dir":"Articles","previous_headings":"Mathematical Formulation","what":"The Generalized PCA Problem","title":"genpca: Generalized PCA and Related Decompositions","text":"GPCA seeks low‑rank approximation XX minimizes reconstruction error metric‑weighted sense. Given row metric MM column metric AA, find rank‑kk factors minimizing: ∥X−UDV⊤∥M,A2=tr(M(X−UDV⊤)(X−UDV⊤)⊤). \\lVert X - U D V^\\top \\rVert_{M,}^2 = \\operatorname{tr}\\!\\Big( M\\, (X - U D V^\\top)\\, \\, (X - U D V^\\top)^\\top \\Big). weighted Frobenius norm incorporates metrics distance calculation. solution satisfies orthonormality constraints respective metrics: U⊤MU=IkU^\\top M U = I_k (M‑orthonormal scores) V⊤AV=IkV^\\top V = I_k (‑orthonormal loadings)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"geometric-interpretation","dir":"Articles","previous_headings":"Mathematical Formulation","what":"Geometric Interpretation","title":"genpca: Generalized PCA and Related Decompositions","text":"metrics M define inner products—thus norms distances—observation variable spaces. weighting, correlation structure, smoothness incorporated principled way. example, choosing M proportional precision (inverse covariance) emphasizes directions higher effective information, diagonal M implements row weighting. M = = , recover ordinary Euclidean geometry standard PCA.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"getting-started-standard-pca-as-gpca","dir":"Articles","previous_headings":"","what":"Getting Started: Standard PCA as GPCA","title":"genpca: Generalized PCA and Related Decompositions","text":"Now understand mathematical framework, let’s see GPCA action. ’ll begin standard PCA establish baseline, progressively introduce metrics demonstrate modify decomposition provide deeper insights data structure. recovers standard PCA since used identity metrics (M = , = ).","code":"set.seed(1) # Simulated data: 200 observations, 50 variables X <- matrix(rnorm(200 * 50), 200, 50)  library(genpca) #> Registered S3 method overwritten by 'genpca': #>   method                   from         #>   transfer.cross_projector multivarious #>  #> Attaching package: 'genpca' #> The following object is masked from 'package:base': #>  #>     truncate # Standard PCA via GPCA (identity metrics by default) fit <- genpca(X, ncomp = 5, preproc = multivarious::center())  # Extract key components cat(\"Top 5 singular values:\\n\") #> Top 5 singular values: print(fit$sdev) #> [1] 21.28910 20.34509 20.05655 19.84090 19.39831  cat(\"\\nExplained variance (first 5 components):\\n\") #>  #> Explained variance (first 5 components): var_explained <- fit$sdev^2 / sum(fit$sdev^2) print(round(var_explained[1:5] * 100, 2)) #> [1] 22.22 20.30 19.72 19.30 18.45  # Scores and components follow multivarious conventions dim(multivarious::scores(fit))      # n × k matrix #> [1] 200   5 dim(multivarious::components(fit))  # p × k matrix #> [1] 50  5"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"weighted-observations-row-metrics","dir":"Articles","previous_headings":"","what":"Weighted Observations: Row Metrics","title":"genpca: Generalized PCA and Related Decompositions","text":"established baseline standard PCA, can now explore row metrics fundamentally change analysis. Consider scenario observations different importance—common situation survey data row might represent responses vastly different population sizes.","code":"library(Matrix)  # Simulate observation weights (e.g., population sizes) n <- nrow(X) obs_weights <- rgamma(n, shape = 2, scale = 0.5) obs_weights <- obs_weights / mean(obs_weights)  # normalize  # Create diagonal row metric M <- Diagonal(n, x = obs_weights)  # GPCA with row weighting fit_weighted <- genpca(X, M = M, ncomp = 5, preproc = multivarious::center())  # Compare with unweighted cat(\"Singular values (unweighted vs weighted):\\n\") #> Singular values (unweighted vs weighted): cbind(Standard = fit$sdev[1:5], Weighted = fit_weighted$sdev[1:5]) #>      Standard Weighted #> [1,] 21.28910 22.88953 #> [2,] 20.34509 21.80008 #> [3,] 20.05655 21.36878 #> [4,] 19.84090 20.82550 #> [5,] 19.39831 19.85992  # The weighted decomposition emphasizes high-weight observations"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"variable-dependencies-column-metrics","dir":"Articles","previous_headings":"","what":"Variable Dependencies: Column Metrics","title":"genpca: Generalized PCA and Related Decompositions","text":"row metrics weight observations, column metrics encode relationships variables. capability becomes crucial dealing variables known correlation structures, measurements taken different spatial locations time points proximity implies similarity.","code":"p <- ncol(X)  # Example: Variables with local correlation structure # Create a tridiagonal matrix that is guaranteed to be PSD # This represents local smoothness constraints library(Matrix)  # Method 1: Simple diagonal weights with small correlations # Create a correlation-like structure that's guaranteed PSD A <- Diagonal(p)  # Start with identity # Add small positive correlations between adjacent variables for (i in 1:(p-1)) {   A[i, i+1] <- 0.2   A[i+1, i] <- 0.2 } # Ensure it's positive definite by adding a small ridge A <- A + 0.1 * Diagonal(p)  # GPCA with column metric fit_corr <- genpca(X, A = A, ncomp = 5, preproc = multivarious::center())  # The decomposition now accounts for variable dependencies cat(\"Effect of column metric on first component:\\n\") #> Effect of column metric on first component: plot(multivarious::components(fit)[,1],       multivarious::components(fit_corr)[,1],      xlab = \"Standard PCA Component\",       ylab = \"GPCA Component (with dependencies)\",      main = \"How column metrics change components\") abline(0, 1, lty = 2, col = \"gray\")"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"computational-methods","dir":"Articles","previous_headings":"","what":"Computational Methods","title":"genpca: Generalized PCA and Related Decompositions","text":"Understanding metrics affect decomposition one aspect GPCA; implementing efficiently scale another. package provides multiple computational backends, optimized different scenarios. method parameter lets select appropriate approach data size computational constraints:","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"method-selection-guide","dir":"Articles","previous_headings":"Computational Methods","what":"Method Selection Guide","title":"genpca: Generalized PCA and Related Decompositions","text":"","code":"# Compare methods on same data library(microbenchmark)  # Small dataset for quick comparison X_small <- matrix(rnorm(100 * 30), 100, 30)  # Time different methods (eval=FALSE for vignette, but instructive) if (FALSE) {   microbenchmark(     eigen = genpca(X_small, ncomp = 5, method = \"eigen\"),     spectra = genpca(X_small, ncomp = 5, method = \"spectra\"),     deflation = genpca(X_small, ncomp = 5, method = \"deflation\"),     times = 10   ) }  # For large sparse problems, spectra is preferred # Note: When using sparse matrices, skip preprocessing or convert to dense n_large <- 500  # Smaller for vignette compilation p_large <- 200 X_sparse <- Matrix::rsparsematrix(n_large, p_large, density = 0.01)  # Convert to regular matrix for preprocessing compatibility # In practice, you might use preproc = multivarious::pass() with sparse matrices X_dense <- as.matrix(X_sparse) fit_large <- genpca(X_dense, ncomp = 10, method = \"spectra\",                      preproc = multivarious::center()) #> 'as(<ddiMatrix>, \"dgCMatrix\")' is deprecated. #> Use 'as(as(., \"generalMatrix\"), \"CsparseMatrix\")' instead. #> See help(\"Deprecated\") and help(\"Matrix-deprecated\")."},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"preprocessing-and-reconstruction","dir":"Articles","previous_headings":"","what":"Preprocessing and Reconstruction","title":"genpca: Generalized PCA and Related Decompositions","text":"computational machinery place, turn critical aspect PCA analysis: preprocessing ability reconstruct data learned components. package’s integration multivarious provides sophisticated preprocessing pipeline ensures numerical stability statistical validity. Centering, particular, typically essential meaningful PCA ensures components capture variance rather dominated mean structure.","code":"# Center columns (variables) before decomposition fit_c <- genpca(X, ncomp = 10, preproc = multivarious::center())  # Examine reconstruction error vs number of components recon_errors <- sapply(1:10, function(k) {   Xhat <- reconstruct(fit_c, comp = 1:k)   mean((X - Xhat)^2) })  plot(1:10, recon_errors, type = \"b\",      xlab = \"Number of Components\",      ylab = \"Mean Squared Reconstruction Error\",      main = \"Reconstruction Quality\") # Typical elbow at 3-4 components for random data cat(\"Reconstruction error with 3 components:\", recon_errors[3], \"\\n\") #> Reconstruction error with 3 components: 0.8937022 cat(\"Percent variance retained:\",      100 * (1 - recon_errors[3]/var(as.vector(X))), \"%\\n\") #> Percent variance retained: 12.79811 %"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"out-of-sample-projection","dir":"Articles","previous_headings":"","what":"Out-of-Sample Projection","title":"genpca: Generalized PCA and Related Decompositions","text":"key strength GPCA lies ability generalize beyond training data. learned decomposition defines projection operator can map new observations component space, making GPCA suitable prediction, validation, transfer learning applications.","code":"# Split data for demonstration n_train <- 150 X_train <- X[1:n_train, ] X_test <- X[(n_train+1):nrow(X), ]  # Fit on training data fit_train <- genpca(X_train, ncomp = 5, preproc = multivarious::center())  # Project test data into learned space scores_test <- multivarious::project(fit_train, X_test)  # Verify dimensions of projected scores cat(\"Test scores dimensions:\", dim(scores_test), \"\\n\") #> Test scores dimensions: 50 5  # For reconstruction error, evaluate on the training split X_train_recon <- multivarious::reconstruct(fit_train, comp = 1:5) train_error <- mean((X_train - X_train_recon)^2) cat(\"Train reconstruction error (5 comps):\", train_error, \"\\n\") #> Train reconstruction error (5 comps): 0.8184143"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"working-with-covariance-matrices","dir":"Articles","previous_headings":"","what":"Working with Covariance Matrices","title":"genpca: Generalized PCA and Related Decompositions","text":"many practical scenarios, may encounter situations raw data matrix unavailable large handle directly, access pre-computed covariance matrix C = X’MX. arises naturally working privacy-protected data, distributed computing systems, covariance computed incrementally streaming data. genpca_cov() function elegantly handles cases performing GPCA directly covariance matrix: genpca_cov() function becomes particularly valuable several scenarios. data matrix X large store memory—perhaps containing millions observations—storing p × p covariance matrix provides enormous memory savings. approach also shines receive pre-computed covariance matrices external sources raw data shared due privacy constraints. Additionally, need explore multiple analyses different column constraints dataset, working covariance matrix allows avoid repeatedly processing raw data.","code":"# Example: Large dataset where we only store the covariance set.seed(789) n <- 1000  # Many observations p <- 50    # Moderate number of variables X_large <- matrix(rnorm(n * p), n, p)  # Row weights (e.g., sample importance) M <- diag(runif(n, 0.5, 1.5))  # Compute and store only the covariance C <- t(X_large) %*% M %*% X_large  # C = X'MX  # Column constraint A <- diag(runif(p, 0.8, 1.2))  # GPCA on covariance (memory-efficient for large n) fit_cov <- genpca_cov(C, R = A, ncomp = 10, method = \"gmd\")  # This is mathematically equivalent to: # genpca(X_large, M = M, A = A, ncomp = 10) # but doesn't require storing the large X matrix  cat(\"Singular values from covariance GPCA:\\n\") #> Singular values from covariance GPCA: print(fit_cov$d[1:5]) #> [1] 38.69639 38.17478 37.65776 37.33684 37.22870"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"generalized-partial-least-squares","dir":"Articles","previous_headings":"","what":"Generalized Partial Least Squares","title":"genpca: Generalized PCA and Related Decompositions","text":"principles GPCA extend naturally two-block methods, seek understand relationships two sets variables. package implements generalized versions Partial Least Squares respect metric structure data blocks, opening powerful possibilities canonical correlation analysis related techniques.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"canonical-correlation-with-metrics","dir":"Articles","previous_headings":"Generalized Partial Least Squares","what":"Canonical Correlation with Metrics","title":"genpca: Generalized PCA and Related Decompositions","text":"package provides generalized PLS-SVD (canonical PLS) finding relationships two data matrices respecting metric structures:","code":"set.seed(2) # Create correlated data blocks n <- 200 # X block: genomic measurements X_pls <- matrix(rnorm(n * 50), n, 50)  # Y block: phenotypic outcomes with some correlation to X shared_signal <- matrix(rnorm(n * 3), n, 3) Y_pls <- shared_signal %*% matrix(rnorm(3 * 20), 3, 20) +           0.5 * matrix(rnorm(n * 20), n, 20)  # Canonical PLS to find shared patterns fit_pls <- genpls(X_pls, Y_pls, ncomp = 3,                   preproc_x = multivarious::center(),                   preproc_y = multivarious::center())  # Examine PLS-SVD singular values and latent correlations cat(\"PLS-SVD singular values (operator):\\n\") #> PLS-SVD singular values (operator): print(round(fit_pls$d, 3)) #> [1] 527.977 397.665 327.720  # If X and Y are standardized, singular values scale with (n-1). # Divide by (n-1) to obtain singular values of the cross-correlation operator. cat(\"\\nSingular values of cross-correlation (d / (n-1)):\\n\") #>  #> Singular values of cross-correlation (d / (n-1)): print(round(fit_pls$d / (n - 1), 3)) #> [1] 2.653 1.998 1.647  # Correlations between paired latent variables (always in [0, 1]) cc <- sapply(seq_len(3), function(j) cor(fit_pls$lx[, j], fit_pls$ly[, j])) cat(\"\\nLatent variable correlations (approx. 'canonical-like'):\\n\") #>  #> Latent variable correlations (approx. 'canonical-like'): print(round(cc, 3)) #> [1] 0.461 0.403 0.453  # The weights show which variables contribute to each canonical variate cat(\"\\nDimensions of weight matrices:\\n\") #>  #> Dimensions of weight matrices: cat(\"X weights:\", dim(fit_pls$vx), \"\\n\") #> X weights: 50 3 cat(\"Y weights:\", dim(fit_pls$vy), \"\\n\") #> Y weights: 20 3"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"low-level-operator-interface","dir":"Articles","previous_headings":"Generalized Partial Least Squares","what":"Low-Level Operator Interface","title":"genpca: Generalized PCA and Related Decompositions","text":"advanced users, gplssvd_op() provides direct access operator-level computations without materializing large intermediate matrices:","code":"# Direct operator SVD (useful for very large problems) op_result <- gplssvd_op(X_pls, Y_pls, k = 3,                         center = TRUE, scale = FALSE)  # Same singular values as high-level interface all.equal(op_result$d, fit_pls$d) #> [1] TRUE"},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"practical-example-weighted-survey-data","dir":"Articles","previous_headings":"","what":"Practical Example: Weighted Survey Data","title":"genpca: Generalized PCA and Related Decompositions","text":"illustrate practical impact generalized metrics, let’s work realistic example survey research. scenario demonstrates just use GPCA, generalized framework provides insights standard PCA miss.","code":"# Simulate survey data where observations represent different population sizes set.seed(123) n_respondents <- 300 n_questions <- 20  # Survey responses (Likert scale 1-5) survey_data <- matrix(sample(1:5, n_respondents * n_questions, replace = TRUE),                       n_respondents, n_questions)  # Population weights (some respondents represent more people) # E.g., stratified sampling with different sampling rates pop_weights <- c(   rep(10, 50),   # Urban areas (undersampled)   rep(2, 100),   # Suburban (representative)   rep(5, 150)    # Rural (slightly undersampled) )  # Standard PCA (treats all respondents equally) pca_unweighted <- genpca(survey_data, ncomp = 5,                           preproc = multivarious::center())  # Weighted GPCA (accounts for population representation) M_survey <- Diagonal(n_respondents, x = pop_weights / mean(pop_weights)) pca_weighted <- genpca(survey_data, M = M_survey, ncomp = 5,                       preproc = multivarious::center())  # Compare first principal component patterns pc1_unweighted <- multivarious::components(pca_unweighted)[,1] pc1_weighted <- multivarious::components(pca_weighted)[,1]  # The weighted analysis gives different importance to questions plot(pc1_unweighted, pc1_weighted,      xlab = \"Unweighted PC1 Components\",      ylab = \"Population-Weighted PC1 Components\",      main = \"Effect of Population Weighting on Principal Components\") abline(0, 1, lty = 2, col = \"red\") text(pc1_unweighted[1:5], pc1_weighted[1:5],       labels = paste0(\"Q\", 1:5), pos = 4, cex = 0.8) cat(\"\\nCorrelation between weighted and unweighted PC1 loadings:\",      cor(pc1_unweighted, pc1_weighted), \"\\n\") #>  #> Correlation between weighted and unweighted PC1 loadings: 0.8749888 cat(\"This shows that population weighting can substantially change the analysis.\\n\") #> This shows that population weighting can substantially change the analysis."},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"best-practices-and-performance-tips","dir":"Articles","previous_headings":"","what":"Best Practices and Performance Tips","title":"genpca: Generalized PCA and Related Decompositions","text":"working genpca package, several practices can dramatically improve performance numerical stability. Matrix sparsity leveraged whenever possible—package designed work efficiently sparse Matrix objects, can reduce memory usage orders magnitude data many zero entries. Choosing right computational method crucial performance. small dense problems fewer 1000 dimensions either direction, eigen method provides straightforward numerically stable approach. data scales becomes sparse, switching spectra method unlocks matrix-free computations can handle datasets large fit memory. need handful components massive dataset, deflation method extracts sequentially, trading computational efficiency minimal memory usage. package’s automatic constraint validation saves numerical pitfalls. provide metric matrices nearly quite positive semi-definite—common occurrence empirical covariance matrices—package automatically detects repairs using principled methods preserve much structure possible. Preprocessing deserves special attention. Unless specific statistical reason avoid , always center data applying GPCA. Centering ensures principal components capture variance rather dominated mean structure. integration multivarious makes straightforward preproc parameter. large datasets exceed available memory, matrix-free spectra method becomes essential. approach never forms full transformed matrices, instead computing matrix-vector products demand. Combined sparse matrix representations, enables GPCA datasets impossible analyze traditional methods.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"genpca: Generalized PCA and Related Decompositions","text":"Allen, G. ., Grosenick, L., & Taylor, J. (2014). generalized least-square matrix decomposition. Journal American Statistical Association, 109(505), 145-159. Beaton, D., ADNI, et al. (2016). Generalized partial least squares: framework simultaneously capturing common individual variation. NeuroImage, 141, 346-363. De Leeuw, J. (2007). Derivatives generalized eigen systems applications. UCLA Department Statistics Papers.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/articles/genpca-overview.html","id":"further-resources","dir":"Articles","previous_headings":"","what":"Further Resources","title":"genpca: Generalized PCA and Related Decompositions","text":"vignette introduced core concepts practical usage Generalized PCA. ready dive deeper, several resources available. companion vignette “Generalized PLS-SVD: Explicit Whitening Reference” provides detailed mathematical derivations connections broader literature matrix decompositions. package documentation (?genpca) offers complete function references additional examples. questions, bug reports, contributions, visit GitHub repository https://github.com/bbuchsbaum/genpca. generalized framework opens rich space possibilities data analysis. encoding prior knowledge metrics, GPCA transforms dimensionality reduction purely data-driven exercise principled integration domain expertise statistical learning.","code":"#> R version 4.5.1 (2025-06-13) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.3 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] microbenchmark_1.5.0 Matrix_1.7-3         genpca_0.1.0         #>  #> loaded via a namespace (and not attached): #>  [1] GPArotation_2025.3-1 sass_0.4.10          future_1.67.0        #>  [4] generics_0.1.4       shape_1.4.6.1        multivarious_0.2.0   #>  [7] lattice_0.22-7       listenv_0.9.1        digest_0.6.37        #> [10] magrittr_2.0.4       evaluate_1.0.5       grid_4.5.1           #> [13] RColorBrewer_1.1-3   iterators_1.0.14     fastmap_1.2.0        #> [16] foreach_1.5.2        glmnet_4.1-10        jsonlite_2.0.0       #> [19] ggrepel_0.9.6        RSpectra_0.16-2      survival_3.8-3       #> [22] scales_1.4.0         pls_2.8-5            codetools_0.2-20     #> [25] textshaping_1.0.3    jquerylib_0.1.4      cli_3.6.5            #> [28] rlang_1.1.6          chk_0.10.0           parallelly_1.45.1    #> [31] future.apply_1.20.0  splines_4.5.1        cachem_1.1.0         #> [34] yaml_2.3.10          FNN_1.1.4.1          tools_4.5.1          #> [37] parallel_4.5.1       dplyr_1.1.4          corpcor_1.6.10       #> [40] ggplot2_4.0.0        PRIMME_3.2-6         globals_0.18.0       #> [43] rsvd_1.0.5           assertthat_0.2.1     vctrs_0.6.5          #> [46] R6_2.6.1             lifecycle_1.0.4      fs_1.6.6             #> [49] irlba_2.3.5.1        ragg_1.5.0           pkgconfig_2.0.3      #> [52] desc_1.4.3           geigen_2.3           pkgdown_2.1.3        #> [55] pillar_1.11.0        bslib_0.9.0          gtable_0.3.6         #> [58] glue_1.8.0           Rcpp_1.1.0           systemfonts_1.2.3    #> [61] xfun_0.53            tibble_3.3.0         tidyselect_1.2.1     #> [64] svd_0.5.8            knitr_1.50           farver_2.1.2         #> [67] htmltools_0.5.8.1    rmarkdown_2.29       compiler_4.5.1       #> [70] S7_0.2.0"},{"path":"https://bbuchsbaum.github.io/genpca/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brad Buchsbaum. Author, maintainer.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Buchsbaum B (2025). genpca: Generalized Principal Component Analysis. R package version 0.1.0, https://bbuchsbaum.github.io/genpca/.","code":"@Manual{,   title = {genpca: Generalized Principal Component Analysis},   author = {Brad Buchsbaum},   year = {2025},   note = {R package version 0.1.0},   url = {https://bbuchsbaum.github.io/genpca/}, }"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"genpca","dir":"","previous_headings":"","what":"Generalized Principal Component Analysis","title":"Generalized Principal Component Analysis","text":"R package Generalized Principal Component Analysis (GPCA) related matrix decompositions data observed non-Euclidean inner-product spaces.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"what-is-generalized-pca","dir":"","previous_headings":"","what":"What is Generalized PCA?","title":"Generalized Principal Component Analysis","text":"Standard PCA assumes observations variables equally important Euclidean distance appropriate similarity measure. However, many real-world datasets violate assumptions: Weighted observations: Survey data rows represent different population sizes Variable precision: Measurements different accuracies importance Correlated features: Spatial/temporal data known dependency structures Domain-specific geometry: Functional data, shape analysis, specialized metrics GPCA extends standard PCA incorporating row column metrics (M ) encode prior knowledge data structure, following framework Allen, Grosenick & Taylor (2014). package also implements generalized PLS methods building ideas Beaton et al. (2016).","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"core-functionality","dir":"","previous_headings":"Key Features","what":"Core Functionality","title":"Generalized Principal Component Analysis","text":"Generalized PCA (genpca): Decomposition row metric M column metric Covariance-based GPCA (genpca_cov): Direct analysis pre-computed covariance matrices eigen: Direct eigendecomposition small--medium problems spectra: Matrix-free C++ implementation large/sparse data deflation: Sequential extraction memory-constrained scenarios","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"advanced-methods","dir":"","previous_headings":"Key Features","what":"Advanced Methods","title":"Generalized Principal Component Analysis","text":"Generalized PLS/PLS-SVD (genpls/genplsc): Two-block analysis metrics Operator-level computations (gplssvd_op): Efficient PLS without materializing whitened matrices Constraint handling: Automatic validation repair metric matrices (PSD enforcement)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"integration","dir":"","previous_headings":"Key Features","what":"Integration","title":"Generalized Principal Component Analysis","text":"Full compatibility multivarious package ecosystem Unified interface preprocessing, projection, reconstruction, transfer learning Support sparse matrices via Matrix package","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Generalized Principal Component Analysis","text":"’ll also want runtime dependencies installed:","code":"# install.packages(\"devtools\") devtools::install_github(\"bbuchsbaum/genpca\") install.packages(c(\"Matrix\", \"RSpectra\", \"multivarious\")) # Optional for some utilities / tests install.packages(c(\"irlba\", \"knitr\", \"rmarkdown\"))"},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"basic-usage","dir":"","previous_headings":"Quick Start","what":"Basic Usage","title":"Generalized Principal Component Analysis","text":"","code":"library(genpca) set.seed(1) X <- matrix(rnorm(200 * 50), 200, 50)  # Standard PCA (identity metrics by default) fit <- genpca(X, ncomp = 5, preproc = multivarious::center()) fit$sdev                             # singular values head(multivarious::scores(fit))      # scores (n × k) head(multivarious::components(fit))  # loadings (p × k)"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"weighted-gpca","dir":"","previous_headings":"Quick Start","what":"Weighted GPCA","title":"Generalized Principal Component Analysis","text":"","code":"# Example: Survey data with population weights library(Matrix) pop_weights <- runif(nrow(X), 0.5, 1.5)  # population sizes M <- Diagonal(nrow(X), x = pop_weights)  # row metric  # Variable importance weights   var_importance <- c(rep(2, 10), rep(1, 30), rep(0.5, 10)) A <- Diagonal(ncol(X), x = var_importance)  # column metric  fit_weighted <- genpca(X, M = M, A = A, ncomp = 5,                        preproc = multivarious::center())"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"covariance-based-gpca","dir":"","previous_headings":"Quick Start","what":"Covariance-based GPCA","title":"Generalized Principal Component Analysis","text":"","code":"# When you have pre-computed covariance C = X'MX C <- crossprod(X, M %*% X) fit_cov <- genpca_cov(C, R = A, ncomp = 5, method = \"gmd\") # Mathematically equivalent to fit_weighted above"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"generalized-pls","dir":"","previous_headings":"Quick Start","what":"Generalized PLS","title":"Generalized Principal Component Analysis","text":"","code":"# Two-block analysis with canonical PLS Y <- matrix(rnorm(200 * 20), 200, 20) pls <- genpls(X, Y, ncomp = 3,                preproc_x = multivarious::center(),                preproc_y = multivarious::center()) pls$d                    # canonical correlations dim(pls$vx); dim(pls$vy) # X/Y weight matrices"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"understanding-metrics-in-gpca","dir":"","previous_headings":"","what":"Understanding Metrics in GPCA","title":"Generalized Principal Component Analysis","text":"metrics M define inner products distances observation variable spaces:","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"row-metric-m-n--n","dir":"","previous_headings":"Understanding Metrics in GPCA","what":"Row Metric M (n × n)","title":"Generalized Principal Component Analysis","text":"Defines relationships observations Inner product: ||x||_M^2 = x^T M x Distance: d_M(x,y)^2 = (x−y)^T M (x−y) Identity: Standard equal weighting Diagonal: Population/sample weights Precision matrix: Account observation correlations Kernel matrices: Encode similarity structures","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"column-metric-a-p--p","dir":"","previous_headings":"Understanding Metrics in GPCA","what":"Column Metric A (p × p)","title":"Generalized Principal Component Analysis","text":"Defines relationships variables Inner product: ||v||_A^2 = v^T v Distance: d_A(v,w)^2 = (v−w)^T (v−w) Identity: Standard equal importance Diagonal: Variable weights/importance Covariance/precision: Variable dependencies Graph Laplacian: Spatial/temporal smoothness M = = , GPCA reduces standard PCA.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Generalized Principal Component Analysis","text":"genpca: Generalized PCA Related Decompositions (overview) Generalized PLS‑SVD: Explicit Whitening Reference (operator vs explicit whitening) Build locally:","code":"devtools::build_vignettes() browseVignettes(\"genpca\")"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"testing-and-guarantees","dir":"","previous_headings":"","what":"Testing and guarantees","title":"Generalized Principal Component Analysis","text":"Eigen vs Spectra: unit tests assert tight agreement modest problems (sdev within 1e‑6, scores within 1e‑5 sign). sdev within 1e‑4, subspace agreement via principal angles, scores/components close Procrustes alignment (≈ 1e‑3 relative). Run tests locally:","code":"library(testthat) library(pkgload) pkgload::load_all() testthat::test_dir(\"tests/testthat\")"},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Generalized Principal Component Analysis","text":"methods package based : Allen, G. ., Grosenick, L., & Taylor, J. (2014). generalized least-square matrix decomposition. Journal American Statistical Association, 109(505), 145-159. doi:10.1080/01621459.2013.852978 Beaton, D., ADNI, et al. (2016). Generalized partial least squares: framework simultaneously capturing common individual variation. NeuroImage, 141, 346-363. doi:10.1016/j.neuroimage.2016.07.034 additional theoretical background generalized decompositions, see: Beaton, D. (2020). Generalized eigen, singular value, partial least squares decompositions: GSVD package. arXiv preprint arXiv:2010.14734.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Generalized Principal Component Analysis","text":"MIT (see LICENSE).","code":""},{"path":"https://bbuchsbaum.github.io/genpca/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Generalized Principal Component Analysis","text":"Issues PRs welcome. Please open ticket minimal example, R session info, (relevant) pointer metric matrices reproduce behavior.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/as_weight_operator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Weight Operator Function — as_weight_operator","title":"Create Weight Operator Function — as_weight_operator","text":"Returns closure applies weight matrix W transformations (square root, inverse, combinations thereof) vectors/matrices.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/as_weight_operator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Weight Operator Function — as_weight_operator","text":"","code":"as_weight_operator(W, transpose = FALSE, sqrt = FALSE, inverse = FALSE)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/as_weight_operator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Weight Operator Function — as_weight_operator","text":"W weight matrix (SPD) NULL identity transpose Logical, whether transpose W applying sqrt Logical, whether use square root W inverse Logical, whether use inverse W","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/as_weight_operator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Weight Operator Function — as_weight_operator","text":"function applies requested transformation","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/constraints_utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for constraints — constraints_utils","title":"Utilities for constraints — constraints_utils","text":"Helpers make constraint matrices symmetric positive definite (SPD).","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/dot-gmd_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal cache for GMD factorizations — .gmd_cache","title":"Internal cache for GMD factorizations — .gmd_cache","text":"Internal cache GMD factorizations","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/dot-gmd_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal cache for GMD factorizations — .gmd_cache","text":"","code":".gmd_cache"},{"path":"https://bbuchsbaum.github.io/genpca/reference/dot-gmd_cache.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Internal cache for GMD factorizations — .gmd_cache","text":"object class environment length 0.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/ensure_spd.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensure SPD (sparse-friendly) — ensure_spd","title":"Ensure SPD (sparse-friendly) — ensure_spd","text":"Force symmetric matrix symmetric positive definite (SPD). Uses Gershgorin-based diagonal shift; falls back nearPD small dense matrices.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/ensure_spd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ensure SPD (sparse-friendly) — ensure_spd","text":"","code":"ensure_spd(M, tol = 1e-06, nearpd_maxn = 2000L)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/ensure_spd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensure SPD (sparse-friendly) — ensure_spd","text":"M numeric matrix Matrix::Matrix tol jitter tolerance (default 1e-8) nearpd_maxn use nearPD n <= nearpd_maxn matrix dense","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/ensure_spd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ensure SPD (sparse-friendly) — ensure_spd","text":"Matrix object (sparse stays sparse possible)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Principal Components Analysis (GPCA) — genpca","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"Implements Generalised Least‑Squares Matrix Decomposition Allen, Grosenick & Taylor (2014) data observed **row** inner‑product space M **column** inner‑product space . Setting M = I_n, = I_p recovers ordinary PCA.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"","code":"genpca(   X,   A = NULL,   M = NULL,   ncomp = NULL,   method = c(\"eigen\", \"spectra\", \"deflation\"),   constraints_remedy = c(\"ridge\", \"error\", \"clip\", \"identity\"),   preproc = multivarious::pass(),   threshold = 1e-06,   use_cpp = TRUE,   maxeig = 800,   warn_approx = TRUE,   maxit_spectra = 1000,   tol_spectra = 1e-09,   verbose = FALSE )  gmdLA(   X,   Q,   R,   k = min(n_orig, p_orig),   n_orig,   p_orig,   maxeig = 800,   tol = 1e-08,   use_dual = FALSE,   warn_approx = TRUE,   verbose = FALSE )  gmd_deflationR(X, Q, R, k, thr = 1e-06, verbose = FALSE)  # S3 method for class 'genpca' truncate(x, ncomp)  # S3 method for class 'genpca' reconstruct(   x,   comp = 1:multivarious::ncomp(x),   rowind = NULL,   colind = NULL,   ... )  # S3 method for class 'genpca' ncomp(x)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"X Numeric matrix n x p. Column constraint: vector (implies diagonal), dense matrix, sparse symmetric p x p PSD matrix. `NULL`, defaults identity. M Row constraint: vector (implies diagonal), dense matrix, sparse symmetric n x n PSD matrix. `NULL`, defaults identity. ncomp Number components extract. Defaults `min(dim(X))`. Must positive. method Character string specifying computation method. One \"eigen\" (default, uses gmdLA), \"spectra\" (uses matrix-free C++/Spectra implementation gmd_fast_cpp), \"deflation\" (uses gmd_deflationR gmd_deflation_cpp). constraints_remedy Character string specifying remedy constraints. One \"error\", \"ridge\", \"clip\", \"identity\". preproc Pre‑processing transformer object **multivarious** package (default `multivarious::pass()`). Use `multivarious::center()` centered GPCA. See `?multivarious::prep` options. threshold Convergence tolerance \"deflation\" method's inner loop. Default `1e-6`. use_cpp Logical. `TRUE` (default) package compiled C++ support, use faster C++ implementation method = \"deflation\". Fallback R otherwise. (Ignored method = \"eigen\" method = \"spectra\"). maxeig Upper bound subspace dimension eigen/SVD calculations, primarily method = \"eigen\". constraint matrix dimension <= maxeig full eigen decomposition used. Otherwise leading maxeig eigencomponents computed via RSpectra::eigs_sym, results may approximate. Default `800`. warn_approx Logical. TRUE (default) warning emitted approximate eigen decomposition used dimension exceeds maxeig. maxit_spectra Maximum iterations Spectra iterative solver method = \"spectra\". Default `1000`. tol_spectra Tolerance Spectra iterative solver method = \"spectra\". Default `1e-9`. verbose Logical. `TRUE`, print progress messages. Default `FALSE`.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"object class `c(\"genpca\", \"bi_projector\")` inheriting `multivarious::bi_projector`,   slots including: u,v Left/right singular vectors scaled constraint metrics                (MU, AV). correspond components original space's geometry.                Use `components(fit)`. ou,ov Orthonormal singular vectors constraint metric                  (U, V UT M U = , VT AV = ). core mathematical factors. sdev Generalised singular values d_k. s Scores ( X V equivalently MU D). Represent projection rows onto components. Use `scores(fit)`. preproc `multivarious` pre‑processing object used. , M constraint matrices used (potentially coercion sparse format). propv Proportion generalized variance explained component. cumv Cumulative proportion generalized variance explained.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"`gmdLA` caches eigen decomposition constraint matrices storing attribute matrix. `compute_sqrtm()` returns modified matrix callers can reassign (e.g. `R <- sqrtm_res$matrix`) reuse cached decomposition subsequent calls.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"method","dir":"Reference","previous_headings":"","what":"Method","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"compute rank‑ncomp factors UDVT minimise $$ \\|X - UDV^\\top\\|_{M,}^2       = \\mathrm{tr}\\!\\bigl(M\\, (X-UDV^\\top)\\,\\,(X-UDV^\\top)^\\top\\bigr) $$ subject UT M U = , VT AV = . (Allen et al., 2014). Three methods available via `method` argument: \"eigen\" (Default): Uses one-shot eigen decomposition strategy based gmdLA. explicitly forms decomposes \\(p \\times p\\) \\(n \\times n\\) matrix (depending n vs p). \"spectra\": Uses matrix-free iterative approach via RcppSpectra package solve eigen problem \"eigen\" without forming large intermediate matrix. Generally faster uses less memory large n p. Requires C++ compiler RcppSpectra. \"deflation\": Uses iterative power/deflation algorithm. Can slower potentially uses less memory \"eigen\" large dense problems ncomp small. pre-computed covariance matrices C = X'MX, see genpca_cov performs GPCA directly C column constraint R (equivalent ).","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"Allen, G. ., Grosenick, L., & Taylor, J. (2014). *Generalized Least‑Squares Matrix Decomposition.* Journal American Statistical Association, 109(505), 145‑159. arXiv:1102.3074.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalised Principal Components Analysis (GPCA) — genpca","text":"","code":"if (requireNamespace(\"RSpectra\", quietly = TRUE) &&     requireNamespace(\"multivarious\", quietly = TRUE)) {   set.seed(123)   X <- matrix(stats::rnorm(200 * 100), 200, 100)   rownames(X) <- paste0(\"R\", 1:200)   colnames(X) <- paste0(\"C\", 1:100)    # Standard PCA (A=I, M=I, centered) - using default method=\"eigen\"   gpca_std_eigen <- genpca(X, ncomp = 5, preproc = multivarious::center(), verbose = FALSE)      # Standard PCA using Spectra method (requires C++ build)   # gpca_std_spectra <- try(genpca(X, ncomp = 5,   #                              preproc = multivarious::center(),   #                              method = \"spectra\", verbose = TRUE))   # if (!inherits(gpca_std_spectra, \"try-error\")) {   #    print(head(gpca_std_spectra$sdev))   # }    # Compare singular values with prcomp   pr_std <- stats::prcomp(X, center = TRUE, scale. = FALSE)   print(\"Eigen Method Sdev:\")   print(head(gpca_std_eigen$sdev))   print(\"prcomp Sdev:\")   print(head(pr_std$sdev))   print(paste(\"Total Var Explained (Eigen):\",               round(sum(gpca_std_eigen$propv) * 100), \"%\"))    # Weighted column PCA (diagonal A, no centering)   col_weights <- stats::runif(100, 0.5, 1.5)   gpca_weighted <- genpca(X, A = col_weights, ncomp = 3,                           preproc = multivarious::pass(), verbose = FALSE)   print(\"Weighted GPCA Sdev:\")   print(gpca_weighted$sdev)   print(head(components(gpca_weighted))) } #> [1] \"Eigen Method Sdev:\" #> [1] 23.38656 23.16950 23.00393 22.56341 22.20862 #> [1] \"prcomp Sdev:\" #> [1] 1.657829 1.642442 1.630705 1.599478 1.574327 1.543299 #> [1] \"Total Var Explained (Eigen): 13 %\" #> [1] \"Weighted GPCA Sdev:\" #> [1] 24.79929 24.23576 23.57776 #> Error in components(gpca_weighted): could not find function \"components\""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized PCA on a covariance matrix — genpca_cov","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"Performs Generalized PCA directly pre-computed covariance matrix C single variable-side constraint/metric R. useful already C = X'MX X large store C manageable. Supports two methods: \"gmd\" (Allen et al.'s GMD approach, default) exactly matches two-sided genpca, \"geigen\" (generalized eigenvalue approach) solves C v = lambda R v.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"","code":"genpca_cov(   C,   R = NULL,   ncomp = NULL,   method = c(\"gmd\", \"geigen\"),   constraints_remedy = c(\"error\", \"ridge\", \"clip\", \"identity\"),   tol = 1e-08,   verbose = FALSE )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"C p x p symmetric positive semi-definite covariance matrix. Typically C = X'MX X data matrix M row metric. R Variable-side constraint/metric. Can : NULL: Identity matrix (standard PCA C) numeric vector length p: Interpreted diagonal weights (must non-negative) p x p symmetric PSD matrix: General metric/smoothing/structure penalties ncomp Number components return. Default positive eigenvalues. method Character string specifying method. One : \"gmd\" (default): Allen et al.'s GMD approach via eigen decomposition R^1/2 C R^1/2 \"geigen\": Generalized eigenvalue approach solving C v = lambda R v constraints_remedy handle slightly non-PSD inputs (geigen method). One : \"error\": Stop error constraints PSD \"ridge\": Add small ridge diagonal make PSD \"clip\": Clip negative eigenvalues zero \"identity\": Replace identity matrix tol Numerical tolerance PSD checks filtering small eigenvalues. Default 1e-8. verbose Logical. TRUE, print progress messages. Default FALSE.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"list components: v p x k matrix loadings (R-orthonormal eigenvectors) d Singular values (square root eigenvalues lambda) lambda Eigenvalues (variances R-metric) k Number components returned propv Proportion variance explained component cumv Cumulative proportion variance explained R_rank Rank constraint matrix R method method used (\"gmd\" \"geigen\")","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"Method Selection Guide: Use method = \"gmd\" : need exact equivalence genpca(X, M, ) following Allen et al.'s GMD framework want consistent results two-sided decomposition Use method = \"geigen\" : specifically need generalized eigenvalue formulation working legacy code expects approach Computational efficiency critical R well-conditioned Method \"gmd\" (default): method implements Allen et al.'s GMD approach exactly matches two-sided genpca C = X'MX. computes eigendecomposition R^1/2 C R^1/2 maps back V = R^-1/2 Z, ensuring V'RV = . total variance tr(CR) Allen's GPCA (Corollary 5). Method \"geigen\": method solves generalized eigenproblem C v = lambda R v directly. mathematically valid, solves different optimization Allen's GMD , general, match two-sided genpca unless R = special commutation conditions hold. exact equivalence genpca(X, M, ), use method=\"gmd\" C = X'MX R = .","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"Allen, G. ., Grosenick, L., & Taylor, J. (2014). Generalized Least-Squares Matrix Decomposition. Journal American Statistical Association, 109(505), 145-159.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized PCA on a covariance matrix — genpca_cov","text":"","code":"# Example 1: Standard PCA on covariance (no constraint) C <- cov(scale(iris[,1:4], center=TRUE, scale=FALSE)) fit0 <- genpca_cov(C, R=NULL, ncomp=3) print(fit0$d[1:3])       # first 3 singular values #> [1] 2.0562689 0.4926162 0.2796596 print(fit0$propv[1:3])   # variance explained by first 3 components #> [1] 0.92461872 0.05306648 0.01710261  # Example 2: Demonstrating equivalence with genpca set.seed(123) X <- matrix(rnorm(50 * 10), 50, 10) M_diag <- runif(50, 0.5, 1.5)  # row weights A_diag <- runif(10, 0.5, 2)    # column weights  # Two-sided GPCA fit_gpca <- genpca(X, M = M_diag, A = A_diag, ncomp = 5,                    preproc = multivarious::pass())  # Equivalent covariance-based GPCA C <- crossprod(X, diag(M_diag) %*% X)  # C = X'MX fit_cov <- genpca_cov(C, R = A_diag, ncomp = 5, method = \"gmd\")  # These should match exactly all.equal(fit_gpca$sdev, fit_cov$d, tolerance = 1e-10) #> [1] TRUE  # Example 3: Variable weights via a diagonal metric w <- c(1, 1, 0.5, 2)  # emphasize Sepal.Width less, Petal.Width more fitW <- genpca_cov(C, R = w, ncomp=3, method=\"gmd\") #> Error in genpca_cov_gmd(C, R, ncomp, tol, verbose): length(R) == p is not TRUE print(fitW$d[1:3]) #> Error: object 'fitW' not found  # Example 4: Compare GMD and generalized eigenvalue approaches fit_gmd <- genpca_cov(C, R = w, ncomp=2, method=\"gmd\") #> Error in genpca_cov_gmd(C, R, ncomp, tol, verbose): length(R) == p is not TRUE fit_geigen <- genpca_cov(C, R = w, ncomp=2, method=\"geigen\") #> Error in genpca_cov_geigen(C, R, ncomp, constraints_remedy, tol, verbose): Length of weight vector R must match ncol(C). # These will generally differ unless R = I print(paste(\"GMD singular values:\", paste(round(fit_gmd$d, 3), collapse=\", \"))) #> Error: object 'fit_gmd' not found print(paste(\"GEigen singular values:\", paste(round(fit_geigen$d, 3), collapse=\", \"))) #> Error: object 'fit_geigen' not found"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov_geigen.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized eigenvalue-based covariance GPCA (internal) — genpca_cov_geigen","title":"Generalized eigenvalue-based covariance GPCA (internal) — genpca_cov_geigen","text":"Solves generalized eigenproblem C v = lambda R v directly. original implementation gpca.R.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov_geigen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized eigenvalue-based covariance GPCA (internal) — genpca_cov_geigen","text":"","code":"genpca_cov_geigen(   C,   R = NULL,   ncomp = NULL,   constraints_remedy = c(\"error\", \"ridge\", \"clip\", \"identity\"),   tol = 1e-08,   verbose = FALSE )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov_gmd.html","id":null,"dir":"Reference","previous_headings":"","what":"GMD-based covariance GPCA (internal) — genpca_cov_gmd","title":"GMD-based covariance GPCA (internal) — genpca_cov_gmd","text":"Implements Allen et al.'s GMD approach covariance matrices. Computes eigendecomposition R^1/2 C R^1/2 maps back.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpca_cov_gmd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GMD-based covariance GPCA (internal) — genpca_cov_gmd","text":"","code":"genpca_cov_gmd(C, R = NULL, ncomp = NULL, tol = 1e-08, verbose = FALSE)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"Canonical (two-block) generalized PLS using sparse-friendly implicit matrix–vector products. Solves SVD operator S = t(Xe)  without materializing Xe = Mx^1/2 X Ax^1/2 Ye = ^1/2 Y Ay^1/2.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"","code":"genpls(   X,   Y,   Ax = NULL,   Ay = NULL,   Mx = NULL,   My = NULL,   ncomp = 2,   preproc_x = multivarious::pass(),   preproc_y = multivarious::pass(),   svd_backend = c(\"RSpectra\", \"irlba\"),   svd_opts = list(tol = 1e-07, maxitr = 1000),   verbose = FALSE )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"X Numeric Matrix, n x p. Y Numeric Matrix, n x q. Must n `X`. Ax Column metric X (W_X): vector/diagonal/matrix; `NULL` ⇒ identity. Ay Column metric Y (W_Y): vector/diagonal/matrix; `NULL` ⇒ identity. Mx Row metric X (M_X): vector/diagonal/matrix; `NULL` ⇒ identity. Row metric Y (M_Y): vector/diagonal/matrix; `NULL` ⇒ identity. ncomp Number components extract (rank-k). Default 2. preproc_x, preproc_y Optional `multivarious` preprocessors (e.g., `center()`). Defaults `multivarious::pass()` (-op). svd_backend Character, one `\"RSpectra\"` (default) `\"irlba\"` iterative SVD. neither backend available, dense fallback used small problems materializing S. svd_opts List options passed SVD backend, e.g., `tol`, `maxitr`. verbose Logical; print brief progress messages.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"object class `c(\"genpls\", \"cross_projector\", \"projector\")` :   - vx, vy: X- Y- weights usable `predict/transfer` (stored cross_projector)   - d:     singular values (attached field)   - p, q:  generalized weights W_X^-1/2 u, W_Y^-1/2 v (attached)   - fi,fj: variable/component scores W_X p diag(d), W_Y q diag(d) (attached)   - lx,ly: row latent variables M_X^1/2 X W_X p, M_Y^1/2 Y W_Y q (attached)   - metrics: supplied metrics (attached)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"follows GPLSSVD/PLS-SVD formulation (Beaton, eqs. 10–14): top `ncomp` singular triplets S computed iterative SVD linear maps v -> S v u -> S^T u, implemented metric Cholesky multiplies/solves possible. Works dense sparse `Matrix` inputs constraint metrics. Returns `multivarious::cross_projector` X-/Y-weights (vx, vy) chosen provide natural projection new data (`X  Additional GPLSSVD quantities attached object access: singular values `d`, generalized weights `p`, `q`, variable scores `fi`, `fj`, row latent variables `lx`, `ly`.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"Beaton, Dougal. Generalized eigen, singular value, partial least squares decompositions: GSVD package. (Eqs. 10–14). 2020.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized PLS via Implicit Operator (PLS-SVD / GPLSSVD) — genpls","text":"","code":"if (requireNamespace(\"RSpectra\", quietly = TRUE) &&     requireNamespace(\"multivarious\", quietly = TRUE)) {   set.seed(1)   n <- 100; p <- 40; q <- 30   X <- matrix(rnorm(n*p), n, p)   Y <- matrix(rnorm(n*q), n, q)   w <- runif(n); w <- w/sum(w)   Mx <- My <- Matrix::Diagonal(x = w)   fit <- genpls(X, Y, Mx = Mx, My = My, ncomp = 2,                 preproc_x = multivarious::center(),                 preproc_y = multivarious::center())   fit$d  # singular values } #> [1] 1.401768 1.340951"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genplsc.html","id":null,"dir":"Reference","previous_headings":"","what":"Canonical Generalized PLS (alias) — genplsc","title":"Canonical Generalized PLS (alias) — genplsc","text":"Convenience alias `genpls()`; computes canonical generalized PLS (PLS-SVD/GPLSSVD). See `?genpls` full documentation.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genplsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canonical Generalized PLS (alias) — genplsc","text":"","code":"genplsc(   X,   Y,   Ax = NULL,   Ay = NULL,   Mx = NULL,   My = NULL,   ncomp = 2,   preproc_x = multivarious::pass(),   preproc_y = multivarious::pass(),   svd_backend = c(\"RSpectra\", \"irlba\"),   svd_opts = list(tol = 1e-07, maxitr = 1000),   verbose = FALSE )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/genplsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Canonical Generalized PLS (alias) — genplsc","text":"X Numeric Matrix, n x p. Y Numeric Matrix, n x q. Must n `X`. Ax Column metric X (W_X): vector/diagonal/matrix; `NULL` ⇒ identity. Ay Column metric Y (W_Y): vector/diagonal/matrix; `NULL` ⇒ identity. Mx Row metric X (M_X): vector/diagonal/matrix; `NULL` ⇒ identity. Row metric Y (M_Y): vector/diagonal/matrix; `NULL` ⇒ identity. ncomp Number components extract (rank-k). Default 2. preproc_x, preproc_y Optional `multivarious` preprocessors (e.g., `center()`). Defaults `multivarious::pass()` (-op). svd_backend Character, one `\"RSpectra\"` (default) `\"irlba\"` iterative SVD. neither backend available, dense fallback used small problems materializing S. svd_opts List options passed SVD backend, e.g., `tol`, `maxitr`. verbose Logical; print brief progress messages.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/genplsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Canonical Generalized PLS (alias) — genplsc","text":"See `genpls()`","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/get_chol_lower_dense.html","id":null,"dir":"Reference","previous_headings":"","what":"Get (and cache) a *lower* Cholesky factor for a dense SPD matrix — get_chol_lower_dense","title":"Get (and cache) a *lower* Cholesky factor for a dense SPD matrix — get_chol_lower_dense","text":"Get (cache) *lower* Cholesky factor dense SPD matrix","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/get_chol_lower_dense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get (and cache) a *lower* Cholesky factor for a dense SPD matrix — get_chol_lower_dense","text":"","code":"get_chol_lower_dense(A)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/get_chol_lower_dense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get (and cache) a *lower* Cholesky factor for a dense SPD matrix — get_chol_lower_dense","text":"numeric dense Matrix (SPD). sparse, falls back dense.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/get_chol_lower_dense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get (and cache) a *lower* Cholesky factor for a dense SPD matrix — get_chol_lower_dense","text":"base numeric matrix L (lower triangular) = L","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_clear_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear internal cache for matrix decompositions — gmd_clear_cache","title":"Clear internal cache for matrix decompositions — gmd_clear_cache","text":"Clears internal cache used generalized matrix decomposition functions. can useful free memory working different datasets.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_clear_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear internal cache for matrix decompositions — gmd_clear_cache","text":"","code":"gmd_clear_cache()"},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_clear_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear internal cache for matrix decompositions — gmd_clear_cache","text":"Invisibly returns TRUE clearing cache.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_clear_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear internal cache for matrix decompositions — gmd_clear_cache","text":"","code":"# Clear the internal cache gmd_clear_cache()"},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_fast_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast generalized matrix decomposition (dense/sparse dispatch) — gmd_fast_cpp","title":"Fast generalized matrix decomposition (dense/sparse dispatch) — gmd_fast_cpp","text":"Fast generalized matrix decomposition (dense/sparse dispatch)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_fast_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast generalized matrix decomposition (dense/sparse dispatch) — gmd_fast_cpp","text":"","code":"gmd_fast_cpp(   X,   Q,   R,   k,   tol = 1e-09,   maxit = 1000L,   seed = 1234L,   topk = TRUE,   cache = TRUE )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/gmd_fast_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast generalized matrix decomposition (dense/sparse dispatch) — gmd_fast_cpp","text":"X numeric matrix (n x p) Q, R constraints (weights/metrics) rows/cols k number components tol tolerance maxit maximum iterations (compatibility, ignored new implementation) seed random seed (compatibility, ignored new implementation) topk logical; use top-k symmetric eigen available (ARPACK). Defaults TRUE. cache logical; cache Cholesky factors across calls dense. Defaults TRUE.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gplssvd_op.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized PLS-SVD via Implicit Operator (memory-safe) — gplssvd_op","title":"Generalized PLS-SVD via Implicit Operator (memory-safe) — gplssvd_op","text":"Compute top-k singular triplets S = t(Xe)  materializing whitened matrices Xe = Mx^1/2 X Wx^1/2, Ye = ^1/2 Y Wy^1/2. Works dense/sparse constraints.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gplssvd_op.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized PLS-SVD via Implicit Operator (memory-safe) — gplssvd_op","text":"","code":"gplssvd_op(   X,   Y,   XLW = NULL,   YLW = NULL,   XRW = NULL,   YRW = NULL,   k = 2,   center = FALSE,   scale = FALSE,   svd_backend = c(\"RSpectra\", \"irlba\"),   svd_opts = list(tol = 1e-07, maxitr = 1000) )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/gplssvd_op.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized PLS-SVD via Implicit Operator (memory-safe) — gplssvd_op","text":"X n x matrix (numeric Matrix) Y n x J matrix (numeric Matrix) XLW Row metric X (M_X): NULL/identity, numeric length-n, diagonalMatrix, PSD Matrix YLW Row metric Y (M_Y) XRW Column metric X (W_X) YRW Column metric Y (W_Y) k Number components center, scale Logical; pre-center/scale columns X, Y metrics svd_backend One \"RSpectra\" (default) \"irlba\" svd_opts List options backend (e.g., tol, maxitr)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/gplssvd_op.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized PLS-SVD via Implicit Operator (memory-safe) — gplssvd_op","text":"list elements d, u, v, p, q, fi, fj, lx, ly, k, dims, center, scale","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_identity_or_diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if constraint matrix is identity or purely diagonal with all != 1 — is_identity_or_diag","title":"Check if constraint matrix is identity or purely diagonal with all != 1 — is_identity_or_diag","text":"Check constraint matrix identity purely diagonal != 1","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_identity_or_diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if constraint matrix is identity or purely diagonal with all != 1 — is_identity_or_diag","text":"","code":"is_identity_or_diag(M, eps = 1e-15)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_identity_or_diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if constraint matrix is identity or purely diagonal with all != 1 — is_identity_or_diag","text":"M matrix (often `dsCMatrix`) `NULL`. eps Numeric tolerance","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_identity_or_diag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if constraint matrix is identity or purely diagonal with all != 1 — is_identity_or_diag","text":"TRUE M (Matrix-based) diagonal partial diag","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_spd.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if matrix is SPD — is_spd","title":"Check if matrix is SPD — is_spd","text":"Check matrix symmetric positive semi-definite using Cholesky decomposition","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_spd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if matrix is SPD — is_spd","text":"","code":"is_spd(A, tol = 1e-06)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_spd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if matrix is SPD — is_spd","text":"numeric matrix Matrix::Matrix tol tolerance numerical checks (unused kept compatibility)","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/is_spd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if matrix is SPD — is_spd","text":"logical TRUE SPD, FALSE otherwise","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/plsutils.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Utilities for Partial Eigen, Adaptive Rank, and Sqrt Transforms — plsutils","title":"Internal Utilities for Partial Eigen, Adaptive Rank, and Sqrt Transforms — plsutils","text":"functions used genpls genplscorr handle partial eigen expansions, diagonal/identity shortcuts, adaptive rank selection, row/column transformations data embeddings.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/reconstruct.html","id":null,"dir":"Reference","previous_headings":"","what":"Reconstruct data from a projection — reconstruct","title":"Reconstruct data from a projection — reconstruct","text":"Re-exported multivarious. See reconstruct details.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/reconstruct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reconstruct data from a projection — reconstruct","text":"","code":"reconstruct(x, comp, rowind, colind, ...)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/reconstruct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reconstruct data from a projection — reconstruct","text":"x projection object comp Components use reconstruction rowind Row indices reconstruct colind Column indices reconstruct ... Additional arguments","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/reconstruct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reconstruct data from a projection — reconstruct","text":"Reconstructed data matrix","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"Implements algorithm Allen *et al.* (2013) supervised dimension-reduction optional sparsity (\\(\\ell_1\\)) ridge (\\(\\ell_2\\)) penalties **** generalised extension operates user-supplied quadratic form \\(Q\\).","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"","code":"fit_rpls(   X,   Y,   K = 2,   lambda = 0.1,   penalty = c(\"l1\", \"ridge\"),   Q = NULL,   nonneg = FALSE,   tol = 1e-06,   maxiter = 200,   verbose = FALSE )  rpls(   X,   Y,   K = 2,   lambda = 0.1,   penalty = c(\"l1\", \"ridge\"),   Q = NULL,   nonneg = FALSE,   preproc_x = pass(),   preproc_y = pass(),   tol = 1e-06,   maxiter = 200,   verbose = FALSE,   ... )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"X Numeric matrix \\((n \\times p)\\) — predictors. Y Numeric matrix \\((n \\times q)\\) — responses. K Integer, number latent factors extract. Default `2`. lambda Scalar length-K numeric vector penalties. penalty Either `\"l1\"` (lasso) `\"ridge\"`. Q Optional positive-(semi)definite \\(p \\times p\\) matrix inducing *generalised* PLS. `NULL` ⇒ identity. nonneg Logical, force non-negative loadings penalty = \"l1\". Note: option currently ignored penalty = \"ridge\". tol Relative tolerance inner iterations convergence check. Default `1e-6`. maxiter Maximum number inner iterations per component. Default `200`. verbose Logical; print progress messages component extraction. Default `FALSE`. preproc_x, preproc_y Optional multivarious preprocessing objects (see prep). default pass data unchanged using pass(). ... arguments (e.g., custom stopping criteria implemented) stored returned object (used fit_rpls).","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"object class c(\"rpls\",\"cross_projector\",\"projector\")   least elements vx \\(p \\times K\\) matrix X-loadings. vy \\(q \\times K\\) matrix Y-loadings. ncomp Number components actually extracted (may < K). penalty Penalty type used (`\"l1\"` `\"ridge\"`). preproc_x, preproc_y Pre-processing transforms used. ... parameters like `lambda`, `tol`, `maxiter`, `nonneg`,                `Q` indicator, `verbose` also stored. object supports predict(), project(),   transfer(), coef() multivarious generics.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"Unlike `genpls()` genplsr.R, handles separate row column metrics (`Mx`, `Ax`, ``, `Ay`) Gram–Schmidt orthogonalisation step, `rpls()` uses single metric `Q` simpler penalised updates Allen et al.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"method","dir":"Reference","previous_headings":"","what":"Method","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"routine follows Algorithm 1 Allen *et al.* (2013, *Stat. Anal. Data Min.*, 6 : 302–314) — see paper details. Briefly, component maximises $$\\max_{u,v}\\; v^\\top Q M u - \\lambda \\, P(v)$$ \\(Q = I_p\\) standard RPLS. alternating updates : \\(u \\leftarrow M^\\top Q v / \\|M^\\top Q v\\|_2\\), penalised (possibly non-negative) regression \\(v\\), normalised \\(Q\\)-norm.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"Allen, G. ., Peterson, C., Vannucci, M., &   Maletić-Savatić, M. (2013). *Regularized Partial Least Squares   Application NMR Spectroscopy.* **Statistical Analysis Data   Mining, 6(4)**, 302-314. DOI:10.1002/sam.11169.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/rpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularised / Generalised Partial Least Squares (RPLS / GPLS) — fit_rpls","text":"","code":"# Generate sample data set.seed(123) n <- 50 p <- 20 q <- 10 X <- matrix(rnorm(n * p), n, p) Y <- X[, 1:5] %*% matrix(rnorm(5 * q), 5, q) + matrix(rnorm(n * q), n, q)  # Fit regularized PLS with L1 penalty fit_l1 <- rpls(X, Y, K = 3, lambda = 0.1, penalty = \"l1\") print(fit_l1) #> cross projector:  rpls cross_projector projector  #> input dim (X):  20  #> output dim (X):  3  #> input dim (Y):  10  #> output dim (Y):  3   # Fit regularized PLS with ridge penalty fit_ridge <- rpls(X, Y, K = 3, lambda = 0.1, penalty = \"ridge\") print(fit_ridge) #> cross projector:  rpls cross_projector projector  #> input dim (X):  20  #> output dim (X):  3  #> input dim (Y):  10  #> output dim (Y):  3"},{"path":"https://bbuchsbaum.github.io/genpca/reference/sfpca.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse and Functional Principal Components Analysis (SFPCA) with Spatial Coordinates — second_diff_matrix","title":"Sparse and Functional Principal Components Analysis (SFPCA) with Spatial Coordinates — second_diff_matrix","text":"Performs Sparse Functional PCA data matrix, allowing sparsity smoothness estimated principal components. Includes heuristic estimation penalty parameters. spatial smoothness penalty constructed based provided spatial coordinates.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/sfpca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse and Functional Principal Components Analysis (SFPCA) with Spatial Coordinates — second_diff_matrix","text":"","code":"second_diff_matrix(n)  sfpca(   X,   K,   spat_cds,   lambda_u = NULL,   lambda_v = NULL,   alpha_u = NULL,   alpha_v = NULL,   Omega_u = NULL,   penalty_u = \"l1\",   penalty_v = \"l1\",   uthresh = 0.9,   vthresh = 0.9,   knn = min(6, ncol(X) - 1),   max_iter = 100,   tol = 1e-06,   verbose = FALSE )  construct_spatial_penalty(spat_cds, method = \"distance\", k = 6L)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/sfpca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse and Functional Principal Components Analysis (SFPCA) with Spatial Coordinates — second_diff_matrix","text":"X numeric data matrix dimensions n (observations/time points) p (variables/space). K number principal components estimate. spat_cds matrix spatial coordinates column X (variables). row corresponds spatial dimension (e.g., x, y, z), column corresponds variable. lambda_u Sparsity penalty parameter u. NULL, estimated heuristically. lambda_v Sparsity penalty parameter v. NULL, estimated heuristically. alpha_u Smoothness penalty parameter u. NULL, estimated heuristically. alpha_v Smoothness penalty parameter v. NULL, estimated heuristically. Omega_u positive semi-definite matrix smoothness penalty u. NULL, defaults second differences penalty (sparse matrix). penalty_u penalty function u. Can \"l1\" (lasso), \"scad\", custom function. penalty_v penalty function v. Can \"l1\" (lasso), \"scad\", custom function. uthresh Quantile selecting `lambda_u` estimated. vthresh Quantile selecting `lambda_v` estimated. knn Number nearest neighbours constructing `Omega_v`. max_iter Maximum number iterations alternating optimization. tol Tolerance convergence. verbose Logical; TRUE, prints progress messages.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/sfpca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse and Functional Principal Components Analysis (SFPCA) with Spatial Coordinates — second_diff_matrix","text":"list containing estimated singular values `d`, left singular vectors `u`, right   singular vectors `v`, penalty parameters used.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/sfpca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse and Functional Principal Components Analysis (SFPCA) with Spatial Coordinates — second_diff_matrix","text":"","code":"library(Matrix) set.seed(123) # Simulate a small example due to resource constraints n <- 100  # Number of time points p <- 50   # Number of spatial locations X <- matrix(rnorm(n * p), n, p) # Simulate spatial coordinates spat_cds <- matrix(runif(p * 3), nrow = 3, ncol = p)  # 3D coordinates result <- sfpca(X, K = 2, spat_cds = spat_cds)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/solve_gep_subspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast sub-space solver for a small block of generalized eigen-pairs — solve_gep_subspace","title":"Fast sub-space solver for a small block of generalized eigen-pairs — solve_gep_subspace","text":"Uses pre-conditioned sub-space iteration operator \\(S_2^{-1} S_1\\) (inverse) obtain `q` largest smallest generalized eigen-values/vectors \\(S_1 v = \\lambda S_2 v\\).","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/solve_gep_subspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast sub-space solver for a small block of generalized eigen-pairs — solve_gep_subspace","text":"","code":"solve_gep_subspace(   S1,   S2,   q = 2,   which = c(\"largest\", \"smallest\"),   max_iter = 100,   tol = 1e-06,   V0 = NULL,   seed = NULL,   reg_S = 0.001,   reg_T = 1e-06,   verbose = FALSE )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/solve_gep_subspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast sub-space solver for a small block of generalized eigen-pairs — solve_gep_subspace","text":"S1, S2 Symmetric positive-(semi)definite `dgCMatrix` (dense) matrices dimension \\(d\\times d\\). q Number eigen-pairs required (`q << d`). `\"largest\"` `\"smallest\"`. max_iter, tol Stopping rule - iteration stops `max(abs(lambda_new - lambda_old)/abs(lambda_old)) < tol`. V0 Optional `d x q` initial block (orthonormalised). seed Optional integer seed reproducible random initialisation. reg_S, reg_T Ridge terms added `S1`/`S2` small `q x q` Gram matrix guarantee invertibility. verbose Logical - print convergence info.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/solve_gep_subspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast sub-space solver for a small block of generalized eigen-pairs — solve_gep_subspace","text":"list components values length-`q` numeric vector Ritz eigen-values. vectors `d x q` matrix, columns orthonormal eigen-vectors                    *original* S-inner-product.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/transfer.cross_projector.html","id":null,"dir":"Reference","previous_headings":"","what":"Compatibility wrapper for multivarious::transfer — transfer.cross_projector","title":"Compatibility wrapper for multivarious::transfer — transfer.cross_projector","text":"Provides transfer method accepts `source`/`target` arguments used tests. method forwards `multivarious`'s transfer method expects ``/``.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/transfer.cross_projector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compatibility wrapper for multivarious::transfer — transfer.cross_projector","text":"","code":"# S3 method for class 'cross_projector' transfer(   x,   new_data,   from = NULL,   to = NULL,   source = NULL,   target = NULL,   opts = list(),   ... )"},{"path":"https://bbuchsbaum.github.io/genpca/reference/transfer.cross_projector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compatibility wrapper for multivarious::transfer — transfer.cross_projector","text":"x cross_projector object. new_data New data transfer. Source space (\"X\" \"Y\"). Target space (\"X\" \"Y\"). source Legacy parameter name ``. Deprecated, use `` instead. target Legacy parameter name ``. Deprecated, use `` instead. opts Options list passed multivarious::transfer. ... Additional arguments passed .","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/transfer.cross_projector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compatibility wrapper for multivarious::transfer — transfer.cross_projector","text":"Matrix transferred data.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/transfer.cross_projector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compatibility wrapper for multivarious::transfer — transfer.cross_projector","text":"","code":"# \\donttest{ # Generate sample data set.seed(123) n <- 50 X <- matrix(rnorm(n * 10), n, 10) Y <- matrix(rnorm(n * 8), n, 8)  # Create a cross projector using rpls fit <- rpls(X, Y, K = 2)  # Transfer new X data to Y space new_X <- matrix(rnorm(10 * 10), 10, 10) transferred <- transfer(fit, new_X, from = \"X\", to = \"Y\") #> Error in transfer(fit, new_X, from = \"X\", to = \"Y\"): could not find function \"transfer\" # }"},{"path":"https://bbuchsbaum.github.io/genpca/reference/truncate.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate a projection to fewer components — truncate","title":"Truncate a projection to fewer components — truncate","text":"Re-exported multivarious. See truncate details.","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/truncate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate a projection to fewer components — truncate","text":"","code":"truncate(x, ncomp)"},{"path":"https://bbuchsbaum.github.io/genpca/reference/truncate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate a projection to fewer components — truncate","text":"x projection object ncomp Number components retain","code":""},{"path":"https://bbuchsbaum.github.io/genpca/reference/truncate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate a projection to fewer components — truncate","text":"Truncated projection object","code":""}]
